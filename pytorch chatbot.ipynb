{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90fb7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded2f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389ae30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
      "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
      "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n"
     ]
    }
   ],
   "source": [
    "lines_filepath = \"/Users/gnarlygav/Desktop/folders/active_projects/ai/chatbot/archive/movie_lines.txt\"\n",
    "conv_filepath = \"/Users/gnarlygav/Desktop/folders/active_projects/ai/chatbot/archive/movie_conversations.txt\"\n",
    "\n",
    "# Visualize some lines\n",
    "with open(lines_filepath, 'r', encoding='iso-8859-1') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines[:8]:\n",
    "    print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2ac261",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_fields = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
    "lines = {}\n",
    "with open(lines_filepath, \"r\", encoding=\"iso-8859-1\") as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \")\n",
    "        # Extract fields\n",
    "        lineObj = {}\n",
    "        for i, field in enumerate(line_fields):\n",
    "            lineObj[field] = values[i]\n",
    "        lines[lineObj[\"lineID\"]] = lineObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd217b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line id error: L8805\n",
      "line id error: L8667\n",
      "line id error: L8740\n"
     ]
    }
   ],
   "source": [
    "# Group fields from loadlines into conversations based on \n",
    "conv_fields = [\"characterID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "conversations = []\n",
    "\n",
    "with open(conv_filepath, 'r', encoding='iso-8859-1') as f:\n",
    "    for line in f:\n",
    "        values = line.split(\" +++$+++ \")\n",
    "        # Extract fields\n",
    "        convObj = {}\n",
    "        for i, field in enumerate(conv_fields):\n",
    "            convObj[field] = values[i]\n",
    "        \n",
    "        # convert string result to split\n",
    "        lineIds = eval(convObj[\"utteranceIDs\"])\n",
    "        #reassemble\n",
    "        convObj[\"lines\"] = []\n",
    "        for lineId in lineIds:\n",
    "            try:\n",
    "                convObj[\"lines\"].append(lines[lineId])\n",
    "            except KeyError:\n",
    "                print(\"line id error: \" + lineId)\n",
    "                pass\n",
    "        conversations.append(convObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f10c52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = []\n",
    "for conversation in conversations:\n",
    "    # iterate\n",
    "    for i in range(len(conversation[\"lines\"]) - 1):\n",
    "        inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "        targetLine = conversation[\"lines\"][i + 1][\"text\"].strip()\n",
    "        #filter wrong samples\n",
    "        if inputLine and targetLine:\n",
    "            qa_pairs.append([inputLine, targetLine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "801895bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing new file...\n",
      "done writing!\n"
     ]
    }
   ],
   "source": [
    "datafile = \"/Users/gnarlygav/Desktop/folders/active_projects/ai/chatbot/archive/formatted_movie_lines.txt\"\n",
    "delimiter = '\\t'\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "print('\\nWriting new file...')\n",
    "with open(datafile, 'w', encoding=\"utf-8\") as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter)\n",
    "    for pair in qa_pairs:\n",
    "        writer.writerow(pair)\n",
    "        \n",
    "print(\"done writing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c394bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\tWell, I thought we'd start with pronunciation, if that's okay with you.\n",
      "Well, I thought we'd start with pronunciation, if that's okay with you.\tNot the hacking and gagging and spitting part.  Please.\n",
      "Not the hacking and gagging and spitting part.  Please.\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "You're asking me out.  That's so cute. What's your name again?\tForget it.\n",
      "No, no, it's my fault -- we didn't have a proper introduction ---\tCameron.\n",
      "Cameron.\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
      "The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\tSeems like she could get a date easy enough...\n",
      "Why?\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\n"
     ]
    }
   ],
   "source": [
    "# visualize\n",
    "datafile = \"/Users/gnarlygav/Desktop/folders/active_projects/ai/chatbot/archive/formatted_movie_lines.txt\"\n",
    "with open(datafile, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines[:8]:\n",
    "    print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b04c1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0 # padding short sentences\n",
    "SOS_token = 1 # start of sentence token <START>\n",
    "EOS_token = 2 # end of sentence token <END>\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}        \n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}        \n",
    "        self.num_words = 3 # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    # Remove words below certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        keep_words = []\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "        \n",
    "        print(\"keep words {} / {} = {:.4f}\".format(len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)))\n",
    "        \n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}        \n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}        \n",
    "        self.num_words = 3 # Count SOS, EOS, PAD\n",
    "        \n",
    "        for word in keep_words:\n",
    "            self.addWord(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a29b7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fea18c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec9a6c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa aa !s s dd ?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizeString(\"aa123aa!s's   dd?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd1581",
   "metadata": {},
   "source": [
    "# DEFINE THE CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c44d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file...\n",
      "Done reading\n"
     ]
    }
   ],
   "source": [
    "datafile = \"/Users/gnarlygav/Desktop/folders/active_projects/ai/chatbot/archive/formatted_movie_lines.txt\"\n",
    "\n",
    "print(\"Reading file...\")\n",
    "lines = open(datafile, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "\n",
    "pairs = [[normalizeString(s) for s in pair.split('\\t')] for pair in lines]\n",
    "print(\"Done reading\")\n",
    "\n",
    "voc = Vocabulary(\"GrowVocab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4be3cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "def filterPair(p):\n",
    "    return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52cf7163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well i thought we d start with pronunciation if that s okay with you .',\n",
       " 'not the hacking and gagging and spitting part . please .']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e9891ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 221279 pairs/conversations\n",
      "There are 64270 pairs/conversations\n"
     ]
    }
   ],
   "source": [
    "pairs = [pair for pair in pairs if len(pair) > 1]\n",
    "print(\"There are {} pairs/conversations\".format(len(pairs)))\n",
    "pairs = filterPairs(pairs)\n",
    "print(\"There are {} pairs/conversations\".format(len(pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d6675fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted words:  18008\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs:\n",
    "    voc.addSentence(pair[0])\n",
    "    voc.addSentence(pair[1])\n",
    "    \n",
    "print(\"Counted words: \", voc.num_words)\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b58dc600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep words 7823 / 18005 = 0.4345\n",
      "Trimmed from 64270 pairs to 53164, 0.827198 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    voc.trim(MIN_COUNT)\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_s = pair[0]\n",
    "        output_s = pair[1]\n",
    "        keep_i = True\n",
    "        keep_o = True\n",
    "        # Check input sentence\n",
    "        for word in input_s.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_i = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_s.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_o = False\n",
    "                break\n",
    "                \n",
    "        if keep_i and keep_o:\n",
    "            keep_pairs.append(pair)\n",
    "            \n",
    "    print(\"Trimmed from {} pairs to {}, {:4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b814d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(\" \")] + [EOS_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3fc8aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you have my word . as a gentleman'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58ddd8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 9, 10, 4, 11, 12, 13, 2]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexesFromSentence(voc, pairs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57917812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there .', 'you have my word . as a gentleman', 'hi .', 'have fun tonight ?', 'well no . . .', 'then that s all you had to say .', 'but', 'do you listen to this crap ?', 'what good stuff ?', 'wow']\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 4, 2],\n",
       " [7, 8, 9, 10, 4, 11, 12, 13, 2],\n",
       " [16, 4, 2],\n",
       " [8, 31, 22, 6, 2],\n",
       " [33, 34, 4, 4, 4, 2],\n",
       " [35, 36, 37, 38, 7, 39, 40, 41, 4, 2],\n",
       " [42, 2],\n",
       " [47, 7, 48, 40, 45, 49, 6, 2],\n",
       " [50, 51, 52, 6, 2],\n",
       " [58, 2]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples for testing\n",
    "inp = []\n",
    "out = []\n",
    "i = 0\n",
    "for pair in pairs[:10]:\n",
    "    inp.append(pair[0])\n",
    "    out.append(pair[1])\n",
    "    \n",
    "print(inp)\n",
    "print(len(inp))\n",
    "indexes = [indexesFromSentence(voc, s) for s in inp]\n",
    "indexes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0d32ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58),\n",
       " (4, 8, 4, 31, 34, 36, 2, 7, 51, 2),\n",
       " (2, 9, 2, 22, 4, 37, 0, 48, 52, 0),\n",
       " (0, 10, 0, 6, 4, 38, 0, 40, 6, 0),\n",
       " (0, 4, 0, 2, 4, 7, 0, 45, 2, 0),\n",
       " (0, 11, 0, 0, 2, 39, 0, 49, 0, 0),\n",
       " (0, 12, 0, 0, 0, 40, 0, 6, 0, 0),\n",
       " (0, 13, 0, 0, 0, 41, 0, 2, 0, 0),\n",
       " (0, 2, 0, 0, 0, 4, 0, 0, 0, 0),\n",
       " (0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[3, 4, 2],\n",
    " [7, 8, 9, 10, 4, 11, 12, 13, 2],\n",
    " [16, 4, 2],\n",
    " [8, 31, 22, 6, 2],\n",
    " [33, 34, 4, 4, 4, 2],\n",
    " [35, 36, 37, 38, 7, 39, 40, 41, 4, 2],\n",
    " [42, 2],\n",
    " [47, 7, 48, 40, 45, 49, 6, 2],\n",
    " [50, 51, 52, 6, 2],\n",
    " [58, 2]]\n",
    "\n",
    "list(itertools.zip_longest(*a, fillvalue=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03e03b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroPadding(l, fillvalue = 0):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d4d9fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matches our MAX_LENGTH\n",
    "leng = [len(ind) for ind in indexes]\n",
    "max(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29d42850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 7, 16, 8, 33, 35, 42, 47, 50, 58),\n",
       " (4, 8, 4, 31, 34, 36, 2, 7, 51, 2),\n",
       " (2, 9, 2, 22, 4, 37, 0, 48, 52, 0),\n",
       " (0, 10, 0, 6, 4, 38, 0, 40, 6, 0),\n",
       " (0, 4, 0, 2, 4, 7, 0, 45, 2, 0),\n",
       " (0, 11, 0, 0, 2, 39, 0, 49, 0, 0),\n",
       " (0, 12, 0, 0, 0, 40, 0, 6, 0, 0),\n",
       " (0, 13, 0, 0, 0, 41, 0, 2, 0, 0),\n",
       " (0, 2, 0, 0, 0, 4, 0, 0, 0, 0),\n",
       " (0, 0, 0, 0, 0, 2, 0, 0, 0, 0)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = zeroPadding(indexes)\n",
    "print(len(test_result))\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd5a481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryMatrix(l, value=0):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "                \n",
    "    return m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65d4a638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 1, 1, 1, 0, 1, 1, 0],\n",
       " [0, 1, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_result = binaryMatrix(test_result)\n",
    "binary_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9833bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns padded  input sequense tensor and tensor of lengths for the sequences in the batch\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "65ed1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns padded target seq tensor, padding mask and max target len\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    \n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.tensor(mask, dtype=bool)\n",
    "    \n",
    "    padVar = torch.LongTensor(padList)\n",
    "    \n",
    "    return padVar, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c26d3844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    # sort by desc len\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    \n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    \n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    \n",
    "    # assert len(inp) == lengths[0]\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82a05def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[  25,    7,   45, 5798,  274],\n",
      "        [ 132,  118,  994, 1314,    4],\n",
      "        [ 158,   70,  115, 5799,    2],\n",
      "        [  76, 1367, 7137,    4,    0],\n",
      "        [ 281,  862,    4,    2,    0],\n",
      "        [   7, 6176,    2,    0,    0],\n",
      "        [ 118,    6,    0,    0,    0],\n",
      "        [   4,    2,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "lengths: tensor([9, 8, 6, 5, 3])\n",
      "target_variable: tensor([[  25, 3023,   45,  310,   67],\n",
      "        [ 197,    4, 1433,  134,   96],\n",
      "        [ 117,    2, 2230,  177,  783],\n",
      "        [ 118,    0,   29, 5540,   56],\n",
      "        [   7,    0, 2882,   66,   53],\n",
      "        [  40,    0,   66,    2,  519],\n",
      "        [ 755,    0,    2,    0,    4],\n",
      "        [   4,    0,    0,    0,    2],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "mask: tensor([[ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True, False,  True,  True,  True],\n",
      "        [ True, False,  True,  True,  True],\n",
      "        [ True, False,  True,  True,  True],\n",
      "        [ True, False,  True, False,  True],\n",
      "        [ True, False, False, False,  True],\n",
      "        [ True, False, False, False, False]])\n",
      "max_target_len: 9\n"
     ]
    }
   ],
   "source": [
    "# example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab472605",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "1. convert word indexes to embeddings\n",
    "2. pack paded batch of sequences for RNN module\n",
    "3. forward pass through GRU (gated recurrent unit)\n",
    "4. unpack padding\n",
    "5. return output of final hidden state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b3b5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRnn(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRnn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # init GRU\n",
    "        # input size and hidden size are both set to hidden size\n",
    "        # because our input size is a word embedding with number\n",
    "        # of features == hidden size\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # input_seq = batch of input sentences; shape=(max_length, batch_size)\n",
    "        # input_lengths = list of sentence lengths corresponding to each sentence in the batch\n",
    "        # hidden state, of shape: (n_layers x num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        # convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        \n",
    "        # pack padded batch of sequenes for rnn module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        \n",
    "        # forward pass through gpu\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        # unpack padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "\n",
    "        # sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "        \n",
    "        return outputs, hidden\n",
    "        # outputs: the output features h_t from the last layer of the GRU, for each timestep (sum of bidirectional outputs)\n",
    "        # outputs shape = (max_length, batch_size, hidden_size)\n",
    "        # hidden: hidden state for the last timestep of shape = (n_layers x num_directions, batch_size, hidden_size)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e8436",
   "metadata": {},
   "source": [
    "# Luong attn layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8bcd5c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden of shape (1, batch_size, hidden_size)\n",
    "        # encoder_outputs of shape (max_length, batch_size, hidden_size)\n",
    "        \n",
    "        # calculate attn weights\n",
    "        attn_energies = self.dot_score(hidden, encoder_outputs) # (max_length, batch_size)\n",
    "        \n",
    "        # transpose max_length and batch_size dim\n",
    "        attn_energies = attn_energies.t()\n",
    "        \n",
    "        # return softmax normalized probability scores with added dim\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cc460c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRnn(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers = 1, dropout = 0.1):\n",
    "        super(LuongAttnDecoderRnn, self).__init__()\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "        \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # input step: one timestep (one word) of input sequence batch; shap = (1, batch_size)\n",
    "        # last_hidden: final hidden layer of GRU; shape=(n_layers x num_directinos, batch_size, hidden_size)\n",
    "        # encoder_outputs: encoder models output; shape=(max_length, batch_size, hidden_size)\n",
    "        # NOTE - ran one word at a time\n",
    "        \n",
    "        # get embedding\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        \n",
    "        # forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # rnn_output shape = (num_layers * num_directions, batch, hidden_size)\n",
    "        \n",
    "        # calculate attention weights from curent GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # multiply attn weights to encoder outputs to get new wieghted sum context vextor\n",
    "        # (batch_size, 1, max_length) bmm with (batch_size, max_length, hidden) = (batch_size,1, hidden)\n",
    "        \n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        \n",
    "        # concat weighted vector and gru output\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        \n",
    "        # predict next word using luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        \n",
    "        # return output of final hidden state\n",
    "        return output, hidden\n",
    "    \n",
    "        # output: softmax normalized tensor giving probability of each word being correct next word in the decoded sequence\n",
    "        # shape=(batch_size, voc.num_words)\n",
    "        # hidden: final hidden state of GRU\n",
    "        # shape = (n_layers x num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e8391e",
   "metadata": {},
   "source": [
    "# Training code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ccde20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(decoder_out, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    target = target.view(-1, 1)\n",
    "    # decoder out shape = (batch_size, vocab_size) target_size = (batch_size, 1)\n",
    "    gathered_tensor = torch.gather(decoder_out, 1, target)\n",
    "    #calculate negative log likelihood loss\n",
    "    crossEntropy = -torch.log(gathered_tensor)\n",
    "    \n",
    "    # select non-zero elements\n",
    "    loss = crossEntropy.masked_select(mask)\n",
    "    \n",
    "    # calculate mean of the loss\n",
    "    \n",
    "    loss = loss.mean()\n",
    "    loss = loss.to(device)\n",
    "    \n",
    "    return loss, nTotal.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8048a262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1728, 0.0884, 0.1306, 0.1451, 0.1418, 0.1952, 0.1262],\n",
      "        [0.1651, 0.1880, 0.0842, 0.1919, 0.1411, 0.0944, 0.1351],\n",
      "        [0.1714, 0.1118, 0.1585, 0.1730, 0.1194, 0.1035, 0.1624],\n",
      "        [0.1532, 0.1284, 0.1104, 0.1130, 0.1086, 0.2077, 0.1786],\n",
      "        [0.0979, 0.1485, 0.1905, 0.1000, 0.1172, 0.1859, 0.1601]])\n",
      "tensor([[2],\n",
      "        [1],\n",
      "        [5],\n",
      "        [4],\n",
      "        [0]])\n",
      "tensor([[0.1306],\n",
      "        [0.1880],\n",
      "        [0.1035],\n",
      "        [0.1086],\n",
      "        [0.0979]])\n",
      "torch.Size([5, 1])\n",
      "cross entropy\n",
      "tensor([[2.0356],\n",
      "        [1.6713],\n",
      "        [2.2685],\n",
      "        [2.2199],\n",
      "        [2.3243]])\n",
      "loss:\n",
      "tensor([2.0356, 2.2685, 2.2199])\n",
      "torch.Size([3])\n",
      "sum of mask elements - how many we consider: tensor(3)\n",
      "mean of loss: tensor(2.1747)\n",
      "mean of cross entropy loss without masking: tensor(2.1039)\n"
     ]
    }
   ],
   "source": [
    "# visualize what's happening\n",
    "\n",
    "dec_o = torch.rand(5,7)\n",
    "dec_o = F.softmax(dec_o, dim=1)\n",
    "tar = torch.tensor([2,1,5,4,0], dtype=torch.long)\n",
    "tar = tar.view(-1,1)\n",
    "mask = torch.tensor([1,0,1,1,0], dtype=torch.bool)\n",
    "print(dec_o)\n",
    "print(tar)\n",
    "\n",
    "gath_ten = torch.gather(dec_o, 1, tar) # softmax scores\n",
    "print(gath_ten)\n",
    "print(gath_ten.shape)\n",
    "crossEntropy = -torch.log(gath_ten)\n",
    "\n",
    "print(\"cross entropy\")\n",
    "print(crossEntropy)\n",
    "\n",
    "mask = mask.unsqueeze(1)\n",
    "loss = crossEntropy.masked_select(mask)\n",
    "\n",
    "print(\"loss:\")\n",
    "print(loss)\n",
    "print(loss.shape)\n",
    "\n",
    "print(\"sum of mask elements - how many we consider:\", mask.sum())\n",
    "print(\"mean of loss:\", loss.mean())\n",
    "print(\"mean of cross entropy loss without masking:\", crossEntropy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0ae7c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_var shape: torch.Size([7, 5])\n",
      "lengths shape: torch.Size([5])\n",
      "target_var shape: torch.Size([10, 5])\n",
      "mask shape: torch.Size([10, 5])\n",
      "max_target_length: 10\n",
      "Encoder outputs shape: torch.Size([7, 5, 500])\n",
      "Last encoder hidden shape: torch.Size([4, 5, 500])\n",
      "Initial decoder input shape: torch.Size([1, 5])\n",
      "tensor([[1, 1, 1, 1, 1]])\n",
      "INIT DECODER HIDDEN SHAPE: torch.Size([2, 5, 500])\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "every timestep of GRU\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Decoder output shape: torch.Size([5, 18008])\n",
      "Decoder hidden shape: torch.Size([2, 5, 500])\n",
      "Target variable at current timestep before reshaping: tensor([  301, 15179,    91,    26,  6975])\n",
      "Target variable at current timestep shape before reshaping: torch.Size([5])\n",
      "The decoder input shape (reshape the target var): torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([True, True, True, True, True])\n",
      "The mask at the current timestep shape: torch.Size([5])\n",
      "Mask loss: tensor(9.7991, grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.995747566223145]\n",
      "5\n",
      "returned loss: 9.799149513244629\n",
      "\n",
      "\n",
      "-----------------------One timestep done-------------------------\n",
      "\n",
      "\n",
      "Decoder output shape: torch.Size([5, 18008])\n",
      "Decoder hidden shape: torch.Size([2, 5, 500])\n",
      "Target variable at current timestep before reshaping: tensor([ 238,   69,  460,  214, 6955])\n",
      "Target variable at current timestep shape before reshaping: torch.Size([5])\n",
      "The decoder input shape (reshape the target var): torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([True, True, True, True, True])\n",
      "The mask at the current timestep shape: torch.Size([5])\n",
      "Mask loss: tensor(9.7671, grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.995747566223145, 48.835601806640625]\n",
      "10\n",
      "returned loss: 9.783134937286377\n",
      "\n",
      "\n",
      "-----------------------One timestep done-------------------------\n",
      "\n",
      "\n",
      "Decoder output shape: torch.Size([5, 18008])\n",
      "Decoder hidden shape: torch.Size([2, 5, 500])\n",
      "Target variable at current timestep before reshaping: tensor([  26, 1041,    4,  123,   38])\n",
      "Target variable at current timestep shape before reshaping: torch.Size([5])\n",
      "The decoder input shape (reshape the target var): torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([True, True, True, True, True])\n",
      "The mask at the current timestep shape: torch.Size([5])\n",
      "Mask loss: tensor(9.8007, grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.995747566223145, 48.835601806640625, 49.00355339050293]\n",
      "15\n",
      "returned loss: 9.78899351755778\n",
      "\n",
      "\n",
      "-----------------------One timestep done-------------------------\n",
      "\n",
      "\n",
      "Decoder output shape: torch.Size([5, 18008])\n",
      "Decoder hidden shape: torch.Size([2, 5, 500])\n",
      "Target variable at current timestep before reshaping: tensor([ 278, 1508,  463,  124,  194])\n",
      "Target variable at current timestep shape before reshaping: torch.Size([5])\n",
      "The decoder input shape (reshape the target var): torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([True, True, True, True, True])\n",
      "The mask at the current timestep shape: torch.Size([5])\n",
      "Mask loss: tensor(9.8382, grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.995747566223145, 48.835601806640625, 49.00355339050293, 49.19100284576416]\n",
      "20\n",
      "returned loss: 9.801295280456543\n",
      "\n",
      "\n",
      "-----------------------One timestep done-------------------------\n",
      "\n",
      "\n",
      "Decoder output shape: torch.Size([5, 18008])\n",
      "Decoder hidden shape: torch.Size([2, 5, 500])\n",
      "Target variable at current timestep before reshaping: tensor([  4, 145,   9,  42,   4])\n",
      "Target variable at current timestep shape before reshaping: torch.Size([5])\n",
      "The decoder input shape (reshape the target var): torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([True, True, True, True, True])\n",
      "The mask at the current timestep shape: torch.Size([5])\n",
      "Mask loss: tensor(9.8535, grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.995747566223145, 48.835601806640625, 49.00355339050293, 49.19100284576416, 49.267611503601074]\n",
      "25\n",
      "returned loss: 9.811740684509278\n",
      "\n",
      "\n",
      "-----------------------One timestep done-------------------------\n",
      "\n",
      "\n",
      "Decoder output shape: torch.Size([5, 18008])\n",
      "Decoder hidden shape: torch.Size([2, 5, 500])\n",
      "Target variable at current timestep before reshaping: tensor([    2, 11256,  6592,   402,     4])\n",
      "Target variable at current timestep shape before reshaping: torch.Size([5])\n",
      "The decoder input shape (reshape the target var): torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([True, True, True, True, True])\n",
      "The mask at the current timestep shape: torch.Size([5])\n",
      "Mask loss: tensor(9.8192, grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.995747566223145, 48.835601806640625, 49.00355339050293, 49.19100284576416, 49.267611503601074, 49.09585475921631]\n",
      "30\n",
      "returned loss: 9.812979062398275\n",
      "\n",
      "\n",
      "-----------------------One timestep done-------------------------\n",
      "\n",
      "\n",
      "Decoder output shape: torch.Size([5, 18008])\n",
      "Decoder hidden shape: torch.Size([2, 5, 500])\n",
      "Target variable at current timestep before reshaping: tensor([  0, 151, 552,  55,   4])\n",
      "Target variable at current timestep shape before reshaping: torch.Size([5])\n",
      "The decoder input shape (reshape the target var): torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([False,  True,  True,  True,  True])\n",
      "The mask at the current timestep shape: torch.Size([5])\n",
      "Mask loss: tensor(9.7453, grad_fn=<MeanBackward0>)\n",
      "Total: 4\n",
      "[48.995747566223145, 48.835601806640625, 49.00355339050293, 49.19100284576416, 49.267611503601074, 49.09585475921631, 38.98115921020508]\n",
      "34\n",
      "returned loss: 9.805015620063333\n",
      "\n",
      "\n",
      "-----------------------One timestep done-------------------------\n",
      "\n",
      "\n",
      "Decoder output shape: torch.Size([5, 18008])\n",
      "Decoder hidden shape: torch.Size([2, 5, 500])\n",
      "Target variable at current timestep before reshaping: tensor([   0, 1779,    4, 2695,    2])\n",
      "Target variable at current timestep shape before reshaping: torch.Size([5])\n",
      "The decoder input shape (reshape the target var): torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([False,  True,  True,  True,  True])\n",
      "The mask at the current timestep shape: torch.Size([5])\n",
      "Mask loss: tensor(9.7729, grad_fn=<MeanBackward0>)\n",
      "Total: 4\n",
      "[48.995747566223145, 48.835601806640625, 49.00355339050293, 49.19100284576416, 49.267611503601074, 49.09585475921631, 38.98115921020508, 39.09149169921875]\n",
      "38\n",
      "returned loss: 9.80163217845716\n",
      "\n",
      "\n",
      "-----------------------One timestep done-------------------------\n",
      "\n",
      "\n",
      "Decoder output shape: torch.Size([5, 18008])\n",
      "Decoder hidden shape: torch.Size([2, 5, 500])\n",
      "Target variable at current timestep before reshaping: tensor([ 0, 69,  2,  4,  0])\n",
      "Target variable at current timestep shape before reshaping: torch.Size([5])\n",
      "The decoder input shape (reshape the target var): torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([False,  True,  True,  True, False])\n",
      "The mask at the current timestep shape: torch.Size([5])\n",
      "Mask loss: tensor(9.7601, grad_fn=<MeanBackward0>)\n",
      "Total: 3\n",
      "[48.995747566223145, 48.835601806640625, 49.00355339050293, 49.19100284576416, 49.267611503601074, 49.09585475921631, 38.98115921020508, 39.09149169921875, 29.28032398223877]\n",
      "41\n",
      "returned loss: 9.798593823502703\n",
      "\n",
      "\n",
      "-----------------------One timestep done-------------------------\n",
      "\n",
      "\n",
      "Decoder output shape: torch.Size([5, 18008])\n",
      "Decoder hidden shape: torch.Size([2, 5, 500])\n",
      "Target variable at current timestep before reshaping: tensor([0, 2, 0, 2, 0])\n",
      "Target variable at current timestep shape before reshaping: torch.Size([5])\n",
      "The decoder input shape (reshape the target var): torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([False,  True, False,  True, False])\n",
      "The mask at the current timestep shape: torch.Size([5])\n",
      "Mask loss: tensor(9.7819, grad_fn=<MeanBackward0>)\n",
      "Total: 2\n",
      "[48.995747566223145, 48.835601806640625, 49.00355339050293, 49.19100284576416, 49.267611503601074, 49.09585475921631, 38.98115921020508, 39.09149169921875, 29.28032398223877, 19.563770294189453]\n",
      "43\n",
      "returned loss: 9.797816675762798\n",
      "\n",
      "\n",
      "-----------------------One timestep done-------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visualize what's happening for one itt. ONLY for vis\n",
    "\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_var shape:\", input_variable.shape)\n",
    "print(\"lengths shape:\", lengths.shape)\n",
    "print(\"target_var shape:\", target_variable.shape)\n",
    "print(\"mask shape:\", mask.shape)\n",
    "print(\"max_target_length:\", max_target_len)\n",
    "\n",
    "# define params\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "attn_model = 'dot'\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "\n",
    "# define encoder/decoder\n",
    "encoder = EncoderRnn(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRnn(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "# ensure train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# init with learning rate\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.0001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.0001)\n",
    "encoder_optimizer.zero_grad()\n",
    "decoder_optimizer.zero_grad()\n",
    "\n",
    "input_variable = input_variable.to(device)\n",
    "lengths = lengths.to(device)\n",
    "target_variable = target_variable.to(device)\n",
    "mask = mask.to(device)\n",
    "\n",
    "loss = 0\n",
    "print_losses = []\n",
    "n_totals = 0\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "print(\"Encoder outputs shape:\", encoder_outputs.shape)\n",
    "print(\"Last encoder hidden shape:\", encoder_hidden.shape)\n",
    "\n",
    "decoder_input = torch.LongTensor([[SOS_token for _ in range(small_batch_size)]])\n",
    "decoder_input = decoder_input.to(device)\n",
    "print(\"Initial decoder input shape:\", decoder_input.shape)\n",
    "print(decoder_input)\n",
    "\n",
    "# set initial decoder hidden state to the encoders final hidden state\n",
    "decoder_hidden = encoder_hidden[:decoder_n_layers] ## DOUBLE CHECK\n",
    "print(\"INIT DECODER HIDDEN SHAPE:\", decoder_hidden.shape)\n",
    "print(\"\\n\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"every timestep of GRU\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "for t in range(max_target_len):\n",
    "    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    print(\"Decoder output shape:\", decoder_output.shape)\n",
    "    print(\"Decoder hidden shape:\", decoder_hidden.shape)\n",
    "    # teacher forcing\n",
    "    decoder_input = target_variable[t].view(1, -1)\n",
    "    print(\"Target variable at current timestep before reshaping:\", target_variable[t])\n",
    "    print(\"Target variable at current timestep shape before reshaping:\", target_variable[t].shape)\n",
    "    print(\"The decoder input shape (reshape the target var):\", decoder_input.shape)\n",
    "    # calculate and accumulate loss\n",
    "    print(\"The mask at the current timestep:\", mask[t])\n",
    "    print(\"The mask at the current timestep shape:\", mask[t].shape)\n",
    "    mask_loss, nTotal = maskNllLoss(decoder_output, target_variable[t], mask[t])\n",
    "    print(\"Mask loss:\", mask_loss)\n",
    "    print(\"Total:\", nTotal)\n",
    "    loss += mask_loss\n",
    "    print_losses.append(mask_loss.item() * nTotal)\n",
    "    print(print_losses)\n",
    "    n_totals += nTotal\n",
    "    print(n_totals)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    returned_loss = sum(print_losses) / n_totals\n",
    "    \n",
    "    print(\"returned loss:\", returned_loss) \n",
    "    print(\"\\n\")\n",
    "    print(\"-----------------------One timestep done-------------------------\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b1229cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    # Lengths for RNN packing should always be on the CPU\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b45ed573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddb67c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75e0bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36909ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#``attn_model = 'general'``\n",
    "#``attn_model = 'concat'``\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a6af42df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 221279 sentence pairs\n",
      "Trimmed to 64270 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 18008\n",
      "\n",
      "pairs:\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Vocabulary(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "# Returns True if both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using the ``filterPair`` condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "corpus_name = \"movie-corpus\"\n",
    "corpus = os.path.join(\"data\", corpus_name)\n",
    "\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)\n",
    "\n",
    "loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "                    '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "                    '{}_checkpoint.tar'.format(checkpoint_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3ba2b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loadFilename = None\n",
    "\n",
    "# Load model if a ``loadFilename`` is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRnn(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRnn(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "07fb90f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 1; Percent complete: 0.0%; Average loss: 9.8050\n",
      "Iteration: 2; Percent complete: 0.1%; Average loss: 9.6152\n",
      "Iteration: 3; Percent complete: 0.1%; Average loss: 9.3168\n",
      "Iteration: 4; Percent complete: 0.1%; Average loss: 9.0690\n",
      "Iteration: 5; Percent complete: 0.1%; Average loss: 8.3776\n",
      "Iteration: 6; Percent complete: 0.1%; Average loss: 7.9178\n",
      "Iteration: 7; Percent complete: 0.2%; Average loss: 7.5336\n",
      "Iteration: 8; Percent complete: 0.2%; Average loss: 7.0527\n",
      "Iteration: 9; Percent complete: 0.2%; Average loss: 7.1873\n",
      "Iteration: 10; Percent complete: 0.2%; Average loss: 7.0074\n",
      "Iteration: 11; Percent complete: 0.3%; Average loss: 6.4480\n",
      "Iteration: 12; Percent complete: 0.3%; Average loss: 6.3715\n",
      "Iteration: 13; Percent complete: 0.3%; Average loss: 5.9948\n",
      "Iteration: 14; Percent complete: 0.4%; Average loss: 5.9960\n",
      "Iteration: 15; Percent complete: 0.4%; Average loss: 5.7029\n",
      "Iteration: 16; Percent complete: 0.4%; Average loss: 5.5015\n",
      "Iteration: 17; Percent complete: 0.4%; Average loss: 4.9796\n",
      "Iteration: 18; Percent complete: 0.4%; Average loss: 5.1316\n",
      "Iteration: 19; Percent complete: 0.5%; Average loss: 4.6725\n",
      "Iteration: 20; Percent complete: 0.5%; Average loss: 4.8796\n",
      "Iteration: 21; Percent complete: 0.5%; Average loss: 4.7811\n",
      "Iteration: 22; Percent complete: 0.5%; Average loss: 4.6221\n",
      "Iteration: 23; Percent complete: 0.6%; Average loss: 4.9863\n",
      "Iteration: 24; Percent complete: 0.6%; Average loss: 4.8940\n",
      "Iteration: 25; Percent complete: 0.6%; Average loss: 4.9076\n",
      "Iteration: 26; Percent complete: 0.7%; Average loss: 4.5123\n",
      "Iteration: 27; Percent complete: 0.7%; Average loss: 4.4725\n",
      "Iteration: 28; Percent complete: 0.7%; Average loss: 4.5933\n",
      "Iteration: 29; Percent complete: 0.7%; Average loss: 4.6408\n",
      "Iteration: 30; Percent complete: 0.8%; Average loss: 4.3465\n",
      "Iteration: 31; Percent complete: 0.8%; Average loss: 4.2338\n",
      "Iteration: 32; Percent complete: 0.8%; Average loss: 4.3598\n",
      "Iteration: 33; Percent complete: 0.8%; Average loss: 4.5118\n",
      "Iteration: 34; Percent complete: 0.9%; Average loss: 4.2187\n",
      "Iteration: 35; Percent complete: 0.9%; Average loss: 4.3057\n",
      "Iteration: 36; Percent complete: 0.9%; Average loss: 4.2053\n",
      "Iteration: 37; Percent complete: 0.9%; Average loss: 4.2911\n",
      "Iteration: 38; Percent complete: 0.9%; Average loss: 4.4750\n",
      "Iteration: 39; Percent complete: 1.0%; Average loss: 4.2747\n",
      "Iteration: 40; Percent complete: 1.0%; Average loss: 4.6203\n",
      "Iteration: 41; Percent complete: 1.0%; Average loss: 4.3910\n",
      "Iteration: 42; Percent complete: 1.1%; Average loss: 4.3089\n",
      "Iteration: 43; Percent complete: 1.1%; Average loss: 4.4144\n",
      "Iteration: 44; Percent complete: 1.1%; Average loss: 4.3177\n",
      "Iteration: 45; Percent complete: 1.1%; Average loss: 4.1160\n",
      "Iteration: 46; Percent complete: 1.1%; Average loss: 4.2241\n",
      "Iteration: 47; Percent complete: 1.2%; Average loss: 4.2972\n",
      "Iteration: 48; Percent complete: 1.2%; Average loss: 4.3490\n",
      "Iteration: 49; Percent complete: 1.2%; Average loss: 4.3481\n",
      "Iteration: 50; Percent complete: 1.2%; Average loss: 3.9209\n",
      "Iteration: 51; Percent complete: 1.3%; Average loss: 4.2387\n",
      "Iteration: 52; Percent complete: 1.3%; Average loss: 3.9656\n",
      "Iteration: 53; Percent complete: 1.3%; Average loss: 4.2233\n",
      "Iteration: 54; Percent complete: 1.4%; Average loss: 4.0539\n",
      "Iteration: 55; Percent complete: 1.4%; Average loss: 4.4484\n",
      "Iteration: 56; Percent complete: 1.4%; Average loss: 4.1068\n",
      "Iteration: 57; Percent complete: 1.4%; Average loss: 4.5459\n",
      "Iteration: 58; Percent complete: 1.5%; Average loss: 4.0602\n",
      "Iteration: 59; Percent complete: 1.5%; Average loss: 4.0002\n",
      "Iteration: 60; Percent complete: 1.5%; Average loss: 4.3063\n",
      "Iteration: 61; Percent complete: 1.5%; Average loss: 4.3215\n",
      "Iteration: 62; Percent complete: 1.6%; Average loss: 4.4661\n",
      "Iteration: 63; Percent complete: 1.6%; Average loss: 4.0073\n",
      "Iteration: 64; Percent complete: 1.6%; Average loss: 4.1149\n",
      "Iteration: 65; Percent complete: 1.6%; Average loss: 4.0081\n",
      "Iteration: 66; Percent complete: 1.7%; Average loss: 4.0289\n",
      "Iteration: 67; Percent complete: 1.7%; Average loss: 3.9411\n",
      "Iteration: 68; Percent complete: 1.7%; Average loss: 4.3119\n",
      "Iteration: 69; Percent complete: 1.7%; Average loss: 3.8729\n",
      "Iteration: 70; Percent complete: 1.8%; Average loss: 4.2128\n",
      "Iteration: 71; Percent complete: 1.8%; Average loss: 4.1322\n",
      "Iteration: 72; Percent complete: 1.8%; Average loss: 4.2601\n",
      "Iteration: 73; Percent complete: 1.8%; Average loss: 4.0392\n",
      "Iteration: 74; Percent complete: 1.8%; Average loss: 4.0690\n",
      "Iteration: 75; Percent complete: 1.9%; Average loss: 4.0536\n",
      "Iteration: 76; Percent complete: 1.9%; Average loss: 4.0792\n",
      "Iteration: 77; Percent complete: 1.9%; Average loss: 3.9460\n",
      "Iteration: 78; Percent complete: 1.9%; Average loss: 4.2214\n",
      "Iteration: 79; Percent complete: 2.0%; Average loss: 4.3280\n",
      "Iteration: 80; Percent complete: 2.0%; Average loss: 4.0682\n",
      "Iteration: 81; Percent complete: 2.0%; Average loss: 3.7109\n",
      "Iteration: 82; Percent complete: 2.1%; Average loss: 4.3665\n",
      "Iteration: 83; Percent complete: 2.1%; Average loss: 3.8396\n",
      "Iteration: 84; Percent complete: 2.1%; Average loss: 3.9833\n",
      "Iteration: 85; Percent complete: 2.1%; Average loss: 3.9225\n",
      "Iteration: 86; Percent complete: 2.1%; Average loss: 3.8283\n",
      "Iteration: 87; Percent complete: 2.2%; Average loss: 3.7238\n",
      "Iteration: 88; Percent complete: 2.2%; Average loss: 3.9079\n",
      "Iteration: 89; Percent complete: 2.2%; Average loss: 3.9713\n",
      "Iteration: 90; Percent complete: 2.2%; Average loss: 4.0889\n",
      "Iteration: 91; Percent complete: 2.3%; Average loss: 4.2351\n",
      "Iteration: 92; Percent complete: 2.3%; Average loss: 4.0258\n",
      "Iteration: 93; Percent complete: 2.3%; Average loss: 3.8225\n",
      "Iteration: 94; Percent complete: 2.4%; Average loss: 3.9941\n",
      "Iteration: 95; Percent complete: 2.4%; Average loss: 4.3236\n",
      "Iteration: 96; Percent complete: 2.4%; Average loss: 3.9440\n",
      "Iteration: 97; Percent complete: 2.4%; Average loss: 3.9779\n",
      "Iteration: 98; Percent complete: 2.5%; Average loss: 4.1553\n",
      "Iteration: 99; Percent complete: 2.5%; Average loss: 3.8548\n",
      "Iteration: 100; Percent complete: 2.5%; Average loss: 3.9695\n",
      "Iteration: 101; Percent complete: 2.5%; Average loss: 4.0797\n",
      "Iteration: 102; Percent complete: 2.5%; Average loss: 3.9040\n",
      "Iteration: 103; Percent complete: 2.6%; Average loss: 3.8769\n",
      "Iteration: 104; Percent complete: 2.6%; Average loss: 3.9888\n",
      "Iteration: 105; Percent complete: 2.6%; Average loss: 4.0130\n",
      "Iteration: 106; Percent complete: 2.6%; Average loss: 4.0426\n",
      "Iteration: 107; Percent complete: 2.7%; Average loss: 3.8891\n",
      "Iteration: 108; Percent complete: 2.7%; Average loss: 3.8539\n",
      "Iteration: 109; Percent complete: 2.7%; Average loss: 3.9220\n",
      "Iteration: 110; Percent complete: 2.8%; Average loss: 4.1246\n",
      "Iteration: 111; Percent complete: 2.8%; Average loss: 3.9479\n",
      "Iteration: 112; Percent complete: 2.8%; Average loss: 3.8827\n",
      "Iteration: 113; Percent complete: 2.8%; Average loss: 4.1744\n",
      "Iteration: 114; Percent complete: 2.9%; Average loss: 3.8540\n",
      "Iteration: 115; Percent complete: 2.9%; Average loss: 4.0668\n",
      "Iteration: 116; Percent complete: 2.9%; Average loss: 3.9919\n",
      "Iteration: 117; Percent complete: 2.9%; Average loss: 4.0804\n",
      "Iteration: 118; Percent complete: 2.9%; Average loss: 3.9461\n",
      "Iteration: 119; Percent complete: 3.0%; Average loss: 3.8252\n",
      "Iteration: 120; Percent complete: 3.0%; Average loss: 4.0072\n",
      "Iteration: 121; Percent complete: 3.0%; Average loss: 4.0047\n",
      "Iteration: 122; Percent complete: 3.0%; Average loss: 4.1671\n",
      "Iteration: 123; Percent complete: 3.1%; Average loss: 3.7143\n",
      "Iteration: 124; Percent complete: 3.1%; Average loss: 3.8004\n",
      "Iteration: 125; Percent complete: 3.1%; Average loss: 3.8686\n",
      "Iteration: 126; Percent complete: 3.1%; Average loss: 3.6380\n",
      "Iteration: 127; Percent complete: 3.2%; Average loss: 3.7899\n",
      "Iteration: 128; Percent complete: 3.2%; Average loss: 3.9732\n",
      "Iteration: 129; Percent complete: 3.2%; Average loss: 3.9796\n",
      "Iteration: 130; Percent complete: 3.2%; Average loss: 3.9149\n",
      "Iteration: 131; Percent complete: 3.3%; Average loss: 3.9959\n",
      "Iteration: 132; Percent complete: 3.3%; Average loss: 3.8916\n",
      "Iteration: 133; Percent complete: 3.3%; Average loss: 3.9951\n",
      "Iteration: 134; Percent complete: 3.4%; Average loss: 3.8332\n",
      "Iteration: 135; Percent complete: 3.4%; Average loss: 3.9309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 136; Percent complete: 3.4%; Average loss: 3.9543\n",
      "Iteration: 137; Percent complete: 3.4%; Average loss: 3.7804\n",
      "Iteration: 138; Percent complete: 3.5%; Average loss: 3.7501\n",
      "Iteration: 139; Percent complete: 3.5%; Average loss: 3.9322\n",
      "Iteration: 140; Percent complete: 3.5%; Average loss: 3.6991\n",
      "Iteration: 141; Percent complete: 3.5%; Average loss: 3.5920\n",
      "Iteration: 142; Percent complete: 3.5%; Average loss: 3.8408\n",
      "Iteration: 143; Percent complete: 3.6%; Average loss: 3.6926\n",
      "Iteration: 144; Percent complete: 3.6%; Average loss: 3.6449\n",
      "Iteration: 145; Percent complete: 3.6%; Average loss: 3.8903\n",
      "Iteration: 146; Percent complete: 3.6%; Average loss: 4.1004\n",
      "Iteration: 147; Percent complete: 3.7%; Average loss: 4.0002\n",
      "Iteration: 148; Percent complete: 3.7%; Average loss: 3.5880\n",
      "Iteration: 149; Percent complete: 3.7%; Average loss: 3.5840\n",
      "Iteration: 150; Percent complete: 3.8%; Average loss: 4.0521\n",
      "Iteration: 151; Percent complete: 3.8%; Average loss: 3.8420\n",
      "Iteration: 152; Percent complete: 3.8%; Average loss: 3.8195\n",
      "Iteration: 153; Percent complete: 3.8%; Average loss: 3.9178\n",
      "Iteration: 154; Percent complete: 3.9%; Average loss: 4.0320\n",
      "Iteration: 155; Percent complete: 3.9%; Average loss: 4.0385\n",
      "Iteration: 156; Percent complete: 3.9%; Average loss: 3.6555\n",
      "Iteration: 157; Percent complete: 3.9%; Average loss: 3.8821\n",
      "Iteration: 158; Percent complete: 4.0%; Average loss: 3.5818\n",
      "Iteration: 159; Percent complete: 4.0%; Average loss: 3.9666\n",
      "Iteration: 160; Percent complete: 4.0%; Average loss: 3.6642\n",
      "Iteration: 161; Percent complete: 4.0%; Average loss: 3.5669\n",
      "Iteration: 162; Percent complete: 4.0%; Average loss: 3.8641\n",
      "Iteration: 163; Percent complete: 4.1%; Average loss: 4.0361\n",
      "Iteration: 164; Percent complete: 4.1%; Average loss: 3.6941\n",
      "Iteration: 165; Percent complete: 4.1%; Average loss: 3.9245\n",
      "Iteration: 166; Percent complete: 4.2%; Average loss: 3.7714\n",
      "Iteration: 167; Percent complete: 4.2%; Average loss: 3.6995\n",
      "Iteration: 168; Percent complete: 4.2%; Average loss: 3.8666\n",
      "Iteration: 169; Percent complete: 4.2%; Average loss: 3.5440\n",
      "Iteration: 170; Percent complete: 4.2%; Average loss: 3.7349\n",
      "Iteration: 171; Percent complete: 4.3%; Average loss: 3.7434\n",
      "Iteration: 172; Percent complete: 4.3%; Average loss: 3.7813\n",
      "Iteration: 173; Percent complete: 4.3%; Average loss: 3.5881\n",
      "Iteration: 174; Percent complete: 4.3%; Average loss: 3.5035\n",
      "Iteration: 175; Percent complete: 4.4%; Average loss: 3.8683\n",
      "Iteration: 176; Percent complete: 4.4%; Average loss: 3.7068\n",
      "Iteration: 177; Percent complete: 4.4%; Average loss: 3.4704\n",
      "Iteration: 178; Percent complete: 4.5%; Average loss: 3.7790\n",
      "Iteration: 179; Percent complete: 4.5%; Average loss: 4.0817\n",
      "Iteration: 180; Percent complete: 4.5%; Average loss: 4.0488\n",
      "Iteration: 181; Percent complete: 4.5%; Average loss: 3.8726\n",
      "Iteration: 182; Percent complete: 4.5%; Average loss: 3.6444\n",
      "Iteration: 183; Percent complete: 4.6%; Average loss: 3.4803\n",
      "Iteration: 184; Percent complete: 4.6%; Average loss: 3.5376\n",
      "Iteration: 185; Percent complete: 4.6%; Average loss: 3.6668\n",
      "Iteration: 186; Percent complete: 4.7%; Average loss: 3.6777\n",
      "Iteration: 187; Percent complete: 4.7%; Average loss: 3.9025\n",
      "Iteration: 188; Percent complete: 4.7%; Average loss: 3.8423\n",
      "Iteration: 189; Percent complete: 4.7%; Average loss: 3.9022\n",
      "Iteration: 190; Percent complete: 4.8%; Average loss: 3.8749\n",
      "Iteration: 191; Percent complete: 4.8%; Average loss: 3.5673\n",
      "Iteration: 192; Percent complete: 4.8%; Average loss: 3.7970\n",
      "Iteration: 193; Percent complete: 4.8%; Average loss: 3.7583\n",
      "Iteration: 194; Percent complete: 4.9%; Average loss: 3.5017\n",
      "Iteration: 195; Percent complete: 4.9%; Average loss: 3.8963\n",
      "Iteration: 196; Percent complete: 4.9%; Average loss: 3.9067\n",
      "Iteration: 197; Percent complete: 4.9%; Average loss: 3.8406\n",
      "Iteration: 198; Percent complete: 5.0%; Average loss: 3.6096\n",
      "Iteration: 199; Percent complete: 5.0%; Average loss: 3.5628\n",
      "Iteration: 200; Percent complete: 5.0%; Average loss: 3.4570\n",
      "Iteration: 201; Percent complete: 5.0%; Average loss: 3.6194\n",
      "Iteration: 202; Percent complete: 5.1%; Average loss: 3.9591\n",
      "Iteration: 203; Percent complete: 5.1%; Average loss: 3.6909\n",
      "Iteration: 204; Percent complete: 5.1%; Average loss: 3.6168\n",
      "Iteration: 205; Percent complete: 5.1%; Average loss: 3.9161\n",
      "Iteration: 206; Percent complete: 5.1%; Average loss: 3.7210\n",
      "Iteration: 207; Percent complete: 5.2%; Average loss: 3.6340\n",
      "Iteration: 208; Percent complete: 5.2%; Average loss: 3.5493\n",
      "Iteration: 209; Percent complete: 5.2%; Average loss: 3.8051\n",
      "Iteration: 210; Percent complete: 5.2%; Average loss: 3.7193\n",
      "Iteration: 211; Percent complete: 5.3%; Average loss: 4.0125\n",
      "Iteration: 212; Percent complete: 5.3%; Average loss: 3.8753\n",
      "Iteration: 213; Percent complete: 5.3%; Average loss: 3.2805\n",
      "Iteration: 214; Percent complete: 5.3%; Average loss: 3.2855\n",
      "Iteration: 215; Percent complete: 5.4%; Average loss: 3.7063\n",
      "Iteration: 216; Percent complete: 5.4%; Average loss: 3.7616\n",
      "Iteration: 217; Percent complete: 5.4%; Average loss: 3.6836\n",
      "Iteration: 218; Percent complete: 5.5%; Average loss: 3.9190\n",
      "Iteration: 219; Percent complete: 5.5%; Average loss: 3.7621\n",
      "Iteration: 220; Percent complete: 5.5%; Average loss: 3.7087\n",
      "Iteration: 221; Percent complete: 5.5%; Average loss: 3.4792\n",
      "Iteration: 222; Percent complete: 5.5%; Average loss: 3.5816\n",
      "Iteration: 223; Percent complete: 5.6%; Average loss: 3.6651\n",
      "Iteration: 224; Percent complete: 5.6%; Average loss: 3.4322\n",
      "Iteration: 225; Percent complete: 5.6%; Average loss: 3.4457\n",
      "Iteration: 226; Percent complete: 5.7%; Average loss: 3.7036\n",
      "Iteration: 227; Percent complete: 5.7%; Average loss: 3.6107\n",
      "Iteration: 228; Percent complete: 5.7%; Average loss: 3.8282\n",
      "Iteration: 229; Percent complete: 5.7%; Average loss: 3.5533\n",
      "Iteration: 230; Percent complete: 5.8%; Average loss: 3.7834\n",
      "Iteration: 231; Percent complete: 5.8%; Average loss: 3.8449\n",
      "Iteration: 232; Percent complete: 5.8%; Average loss: 3.4807\n",
      "Iteration: 233; Percent complete: 5.8%; Average loss: 3.6030\n",
      "Iteration: 234; Percent complete: 5.9%; Average loss: 3.8719\n",
      "Iteration: 235; Percent complete: 5.9%; Average loss: 3.5768\n",
      "Iteration: 236; Percent complete: 5.9%; Average loss: 3.3524\n",
      "Iteration: 237; Percent complete: 5.9%; Average loss: 3.4858\n",
      "Iteration: 238; Percent complete: 5.9%; Average loss: 3.8505\n",
      "Iteration: 239; Percent complete: 6.0%; Average loss: 3.7445\n",
      "Iteration: 240; Percent complete: 6.0%; Average loss: 3.5414\n",
      "Iteration: 241; Percent complete: 6.0%; Average loss: 3.7783\n",
      "Iteration: 242; Percent complete: 6.0%; Average loss: 3.6397\n",
      "Iteration: 243; Percent complete: 6.1%; Average loss: 3.7605\n",
      "Iteration: 244; Percent complete: 6.1%; Average loss: 3.6615\n",
      "Iteration: 245; Percent complete: 6.1%; Average loss: 3.3984\n",
      "Iteration: 246; Percent complete: 6.2%; Average loss: 3.4451\n",
      "Iteration: 247; Percent complete: 6.2%; Average loss: 3.7516\n",
      "Iteration: 248; Percent complete: 6.2%; Average loss: 3.4081\n",
      "Iteration: 249; Percent complete: 6.2%; Average loss: 3.5701\n",
      "Iteration: 250; Percent complete: 6.2%; Average loss: 3.6231\n",
      "Iteration: 251; Percent complete: 6.3%; Average loss: 3.7562\n",
      "Iteration: 252; Percent complete: 6.3%; Average loss: 3.7017\n",
      "Iteration: 253; Percent complete: 6.3%; Average loss: 3.5906\n",
      "Iteration: 254; Percent complete: 6.3%; Average loss: 3.4274\n",
      "Iteration: 255; Percent complete: 6.4%; Average loss: 3.5681\n",
      "Iteration: 256; Percent complete: 6.4%; Average loss: 3.4361\n",
      "Iteration: 257; Percent complete: 6.4%; Average loss: 3.3890\n",
      "Iteration: 258; Percent complete: 6.5%; Average loss: 3.8074\n",
      "Iteration: 259; Percent complete: 6.5%; Average loss: 3.7828\n",
      "Iteration: 260; Percent complete: 6.5%; Average loss: 3.5362\n",
      "Iteration: 261; Percent complete: 6.5%; Average loss: 3.5911\n",
      "Iteration: 262; Percent complete: 6.6%; Average loss: 3.7438\n",
      "Iteration: 263; Percent complete: 6.6%; Average loss: 3.5495\n",
      "Iteration: 264; Percent complete: 6.6%; Average loss: 3.6214\n",
      "Iteration: 265; Percent complete: 6.6%; Average loss: 3.6115\n",
      "Iteration: 266; Percent complete: 6.7%; Average loss: 3.5595\n",
      "Iteration: 267; Percent complete: 6.7%; Average loss: 3.8774\n",
      "Iteration: 268; Percent complete: 6.7%; Average loss: 3.5514\n",
      "Iteration: 269; Percent complete: 6.7%; Average loss: 3.6973\n",
      "Iteration: 270; Percent complete: 6.8%; Average loss: 3.5062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 271; Percent complete: 6.8%; Average loss: 3.5517\n",
      "Iteration: 272; Percent complete: 6.8%; Average loss: 3.5607\n",
      "Iteration: 273; Percent complete: 6.8%; Average loss: 3.3800\n",
      "Iteration: 274; Percent complete: 6.9%; Average loss: 3.3304\n",
      "Iteration: 275; Percent complete: 6.9%; Average loss: 3.6767\n",
      "Iteration: 276; Percent complete: 6.9%; Average loss: 3.8828\n",
      "Iteration: 277; Percent complete: 6.9%; Average loss: 3.6711\n",
      "Iteration: 278; Percent complete: 7.0%; Average loss: 3.7779\n",
      "Iteration: 279; Percent complete: 7.0%; Average loss: 3.5881\n",
      "Iteration: 280; Percent complete: 7.0%; Average loss: 3.4250\n",
      "Iteration: 281; Percent complete: 7.0%; Average loss: 3.6250\n",
      "Iteration: 282; Percent complete: 7.0%; Average loss: 3.3237\n",
      "Iteration: 283; Percent complete: 7.1%; Average loss: 3.3450\n",
      "Iteration: 284; Percent complete: 7.1%; Average loss: 3.3425\n",
      "Iteration: 285; Percent complete: 7.1%; Average loss: 3.8385\n",
      "Iteration: 286; Percent complete: 7.1%; Average loss: 3.4726\n",
      "Iteration: 287; Percent complete: 7.2%; Average loss: 3.6334\n",
      "Iteration: 288; Percent complete: 7.2%; Average loss: 3.6230\n",
      "Iteration: 289; Percent complete: 7.2%; Average loss: 3.5086\n",
      "Iteration: 290; Percent complete: 7.2%; Average loss: 3.5650\n",
      "Iteration: 291; Percent complete: 7.3%; Average loss: 3.4571\n",
      "Iteration: 292; Percent complete: 7.3%; Average loss: 3.5556\n",
      "Iteration: 293; Percent complete: 7.3%; Average loss: 3.5307\n",
      "Iteration: 294; Percent complete: 7.3%; Average loss: 3.6252\n",
      "Iteration: 295; Percent complete: 7.4%; Average loss: 3.5841\n",
      "Iteration: 296; Percent complete: 7.4%; Average loss: 3.4598\n",
      "Iteration: 297; Percent complete: 7.4%; Average loss: 3.6550\n",
      "Iteration: 298; Percent complete: 7.4%; Average loss: 3.5483\n",
      "Iteration: 299; Percent complete: 7.5%; Average loss: 3.6428\n",
      "Iteration: 300; Percent complete: 7.5%; Average loss: 3.3934\n",
      "Iteration: 301; Percent complete: 7.5%; Average loss: 3.2211\n",
      "Iteration: 302; Percent complete: 7.5%; Average loss: 3.4514\n",
      "Iteration: 303; Percent complete: 7.6%; Average loss: 3.4624\n",
      "Iteration: 304; Percent complete: 7.6%; Average loss: 3.8714\n",
      "Iteration: 305; Percent complete: 7.6%; Average loss: 3.5865\n",
      "Iteration: 306; Percent complete: 7.6%; Average loss: 3.6247\n",
      "Iteration: 307; Percent complete: 7.7%; Average loss: 3.6329\n",
      "Iteration: 308; Percent complete: 7.7%; Average loss: 3.5918\n",
      "Iteration: 309; Percent complete: 7.7%; Average loss: 3.5708\n",
      "Iteration: 310; Percent complete: 7.8%; Average loss: 3.5391\n",
      "Iteration: 311; Percent complete: 7.8%; Average loss: 3.5270\n",
      "Iteration: 312; Percent complete: 7.8%; Average loss: 3.7815\n",
      "Iteration: 313; Percent complete: 7.8%; Average loss: 3.5773\n",
      "Iteration: 314; Percent complete: 7.8%; Average loss: 3.6984\n",
      "Iteration: 315; Percent complete: 7.9%; Average loss: 3.5161\n",
      "Iteration: 316; Percent complete: 7.9%; Average loss: 3.3097\n",
      "Iteration: 317; Percent complete: 7.9%; Average loss: 3.8948\n",
      "Iteration: 318; Percent complete: 8.0%; Average loss: 3.8192\n",
      "Iteration: 319; Percent complete: 8.0%; Average loss: 3.5369\n",
      "Iteration: 320; Percent complete: 8.0%; Average loss: 3.6985\n",
      "Iteration: 321; Percent complete: 8.0%; Average loss: 3.4753\n",
      "Iteration: 322; Percent complete: 8.1%; Average loss: 3.8600\n",
      "Iteration: 323; Percent complete: 8.1%; Average loss: 3.3626\n",
      "Iteration: 324; Percent complete: 8.1%; Average loss: 3.6037\n",
      "Iteration: 325; Percent complete: 8.1%; Average loss: 3.4121\n",
      "Iteration: 326; Percent complete: 8.2%; Average loss: 3.5841\n",
      "Iteration: 327; Percent complete: 8.2%; Average loss: 3.5304\n",
      "Iteration: 328; Percent complete: 8.2%; Average loss: 3.4860\n",
      "Iteration: 329; Percent complete: 8.2%; Average loss: 3.6855\n",
      "Iteration: 330; Percent complete: 8.2%; Average loss: 3.4978\n",
      "Iteration: 331; Percent complete: 8.3%; Average loss: 3.7114\n",
      "Iteration: 332; Percent complete: 8.3%; Average loss: 3.3971\n",
      "Iteration: 333; Percent complete: 8.3%; Average loss: 3.8210\n",
      "Iteration: 334; Percent complete: 8.3%; Average loss: 3.0793\n",
      "Iteration: 335; Percent complete: 8.4%; Average loss: 3.7206\n",
      "Iteration: 336; Percent complete: 8.4%; Average loss: 3.6553\n",
      "Iteration: 337; Percent complete: 8.4%; Average loss: 3.7377\n",
      "Iteration: 338; Percent complete: 8.5%; Average loss: 3.5845\n",
      "Iteration: 339; Percent complete: 8.5%; Average loss: 3.3791\n",
      "Iteration: 340; Percent complete: 8.5%; Average loss: 3.5531\n",
      "Iteration: 341; Percent complete: 8.5%; Average loss: 3.4318\n",
      "Iteration: 342; Percent complete: 8.6%; Average loss: 3.6995\n",
      "Iteration: 343; Percent complete: 8.6%; Average loss: 3.4104\n",
      "Iteration: 344; Percent complete: 8.6%; Average loss: 3.5722\n",
      "Iteration: 345; Percent complete: 8.6%; Average loss: 3.3507\n",
      "Iteration: 346; Percent complete: 8.6%; Average loss: 3.5975\n",
      "Iteration: 347; Percent complete: 8.7%; Average loss: 3.7599\n",
      "Iteration: 348; Percent complete: 8.7%; Average loss: 3.8019\n",
      "Iteration: 349; Percent complete: 8.7%; Average loss: 3.3879\n",
      "Iteration: 350; Percent complete: 8.8%; Average loss: 3.3535\n",
      "Iteration: 351; Percent complete: 8.8%; Average loss: 3.2729\n",
      "Iteration: 352; Percent complete: 8.8%; Average loss: 3.4785\n",
      "Iteration: 353; Percent complete: 8.8%; Average loss: 3.3750\n",
      "Iteration: 354; Percent complete: 8.8%; Average loss: 3.7350\n",
      "Iteration: 355; Percent complete: 8.9%; Average loss: 3.6150\n",
      "Iteration: 356; Percent complete: 8.9%; Average loss: 3.2973\n",
      "Iteration: 357; Percent complete: 8.9%; Average loss: 3.1737\n",
      "Iteration: 358; Percent complete: 8.9%; Average loss: 3.5993\n",
      "Iteration: 359; Percent complete: 9.0%; Average loss: 3.6080\n",
      "Iteration: 360; Percent complete: 9.0%; Average loss: 3.5825\n",
      "Iteration: 361; Percent complete: 9.0%; Average loss: 3.6717\n",
      "Iteration: 362; Percent complete: 9.0%; Average loss: 3.6039\n",
      "Iteration: 363; Percent complete: 9.1%; Average loss: 3.3080\n",
      "Iteration: 364; Percent complete: 9.1%; Average loss: 3.4095\n",
      "Iteration: 365; Percent complete: 9.1%; Average loss: 3.9273\n",
      "Iteration: 366; Percent complete: 9.2%; Average loss: 3.5132\n",
      "Iteration: 367; Percent complete: 9.2%; Average loss: 3.0939\n",
      "Iteration: 368; Percent complete: 9.2%; Average loss: 3.8160\n",
      "Iteration: 369; Percent complete: 9.2%; Average loss: 3.6130\n",
      "Iteration: 370; Percent complete: 9.2%; Average loss: 3.5612\n",
      "Iteration: 371; Percent complete: 9.3%; Average loss: 3.3656\n",
      "Iteration: 372; Percent complete: 9.3%; Average loss: 3.3754\n",
      "Iteration: 373; Percent complete: 9.3%; Average loss: 3.3408\n",
      "Iteration: 374; Percent complete: 9.3%; Average loss: 3.5087\n",
      "Iteration: 375; Percent complete: 9.4%; Average loss: 3.7521\n",
      "Iteration: 376; Percent complete: 9.4%; Average loss: 3.4260\n",
      "Iteration: 377; Percent complete: 9.4%; Average loss: 3.2669\n",
      "Iteration: 378; Percent complete: 9.4%; Average loss: 3.2988\n",
      "Iteration: 379; Percent complete: 9.5%; Average loss: 3.7526\n",
      "Iteration: 380; Percent complete: 9.5%; Average loss: 3.3014\n",
      "Iteration: 381; Percent complete: 9.5%; Average loss: 3.5352\n",
      "Iteration: 382; Percent complete: 9.6%; Average loss: 3.3759\n",
      "Iteration: 383; Percent complete: 9.6%; Average loss: 3.3994\n",
      "Iteration: 384; Percent complete: 9.6%; Average loss: 3.6758\n",
      "Iteration: 385; Percent complete: 9.6%; Average loss: 3.7073\n",
      "Iteration: 386; Percent complete: 9.7%; Average loss: 3.6375\n",
      "Iteration: 387; Percent complete: 9.7%; Average loss: 3.2958\n",
      "Iteration: 388; Percent complete: 9.7%; Average loss: 3.5485\n",
      "Iteration: 389; Percent complete: 9.7%; Average loss: 3.2316\n",
      "Iteration: 390; Percent complete: 9.8%; Average loss: 3.4547\n",
      "Iteration: 391; Percent complete: 9.8%; Average loss: 3.7012\n",
      "Iteration: 392; Percent complete: 9.8%; Average loss: 3.5077\n",
      "Iteration: 393; Percent complete: 9.8%; Average loss: 3.2794\n",
      "Iteration: 394; Percent complete: 9.8%; Average loss: 3.4390\n",
      "Iteration: 395; Percent complete: 9.9%; Average loss: 3.5886\n",
      "Iteration: 396; Percent complete: 9.9%; Average loss: 3.5242\n",
      "Iteration: 397; Percent complete: 9.9%; Average loss: 3.2892\n",
      "Iteration: 398; Percent complete: 10.0%; Average loss: 3.4552\n",
      "Iteration: 399; Percent complete: 10.0%; Average loss: 3.4978\n",
      "Iteration: 400; Percent complete: 10.0%; Average loss: 3.4732\n",
      "Iteration: 401; Percent complete: 10.0%; Average loss: 3.5031\n",
      "Iteration: 402; Percent complete: 10.1%; Average loss: 3.4450\n",
      "Iteration: 403; Percent complete: 10.1%; Average loss: 3.1211\n",
      "Iteration: 404; Percent complete: 10.1%; Average loss: 3.2394\n",
      "Iteration: 405; Percent complete: 10.1%; Average loss: 3.1430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 406; Percent complete: 10.2%; Average loss: 3.4021\n",
      "Iteration: 407; Percent complete: 10.2%; Average loss: 3.5548\n",
      "Iteration: 408; Percent complete: 10.2%; Average loss: 3.3823\n",
      "Iteration: 409; Percent complete: 10.2%; Average loss: 3.6902\n",
      "Iteration: 410; Percent complete: 10.2%; Average loss: 3.5441\n",
      "Iteration: 411; Percent complete: 10.3%; Average loss: 3.4977\n",
      "Iteration: 412; Percent complete: 10.3%; Average loss: 3.4647\n",
      "Iteration: 413; Percent complete: 10.3%; Average loss: 3.4059\n",
      "Iteration: 414; Percent complete: 10.3%; Average loss: 3.3674\n",
      "Iteration: 415; Percent complete: 10.4%; Average loss: 3.2177\n",
      "Iteration: 416; Percent complete: 10.4%; Average loss: 3.1610\n",
      "Iteration: 417; Percent complete: 10.4%; Average loss: 3.2216\n",
      "Iteration: 418; Percent complete: 10.4%; Average loss: 3.5164\n",
      "Iteration: 419; Percent complete: 10.5%; Average loss: 3.4141\n",
      "Iteration: 420; Percent complete: 10.5%; Average loss: 3.3280\n",
      "Iteration: 421; Percent complete: 10.5%; Average loss: 3.9770\n",
      "Iteration: 422; Percent complete: 10.5%; Average loss: 3.3425\n",
      "Iteration: 423; Percent complete: 10.6%; Average loss: 3.6196\n",
      "Iteration: 424; Percent complete: 10.6%; Average loss: 3.5648\n",
      "Iteration: 425; Percent complete: 10.6%; Average loss: 3.3042\n",
      "Iteration: 426; Percent complete: 10.7%; Average loss: 3.3465\n",
      "Iteration: 427; Percent complete: 10.7%; Average loss: 3.6191\n",
      "Iteration: 428; Percent complete: 10.7%; Average loss: 3.4972\n",
      "Iteration: 429; Percent complete: 10.7%; Average loss: 3.4488\n",
      "Iteration: 430; Percent complete: 10.8%; Average loss: 3.3553\n",
      "Iteration: 431; Percent complete: 10.8%; Average loss: 3.5742\n",
      "Iteration: 432; Percent complete: 10.8%; Average loss: 3.7078\n",
      "Iteration: 433; Percent complete: 10.8%; Average loss: 3.6671\n",
      "Iteration: 434; Percent complete: 10.8%; Average loss: 3.5263\n",
      "Iteration: 435; Percent complete: 10.9%; Average loss: 3.2976\n",
      "Iteration: 436; Percent complete: 10.9%; Average loss: 3.3895\n",
      "Iteration: 437; Percent complete: 10.9%; Average loss: 3.5137\n",
      "Iteration: 438; Percent complete: 10.9%; Average loss: 3.5032\n",
      "Iteration: 439; Percent complete: 11.0%; Average loss: 3.7689\n",
      "Iteration: 440; Percent complete: 11.0%; Average loss: 3.5835\n",
      "Iteration: 441; Percent complete: 11.0%; Average loss: 3.5147\n",
      "Iteration: 442; Percent complete: 11.1%; Average loss: 3.5873\n",
      "Iteration: 443; Percent complete: 11.1%; Average loss: 3.2559\n",
      "Iteration: 444; Percent complete: 11.1%; Average loss: 3.4893\n",
      "Iteration: 445; Percent complete: 11.1%; Average loss: 3.4894\n",
      "Iteration: 446; Percent complete: 11.2%; Average loss: 3.4974\n",
      "Iteration: 447; Percent complete: 11.2%; Average loss: 3.4986\n",
      "Iteration: 448; Percent complete: 11.2%; Average loss: 3.2552\n",
      "Iteration: 449; Percent complete: 11.2%; Average loss: 3.3673\n",
      "Iteration: 450; Percent complete: 11.2%; Average loss: 3.4425\n",
      "Iteration: 451; Percent complete: 11.3%; Average loss: 3.2276\n",
      "Iteration: 452; Percent complete: 11.3%; Average loss: 3.4700\n",
      "Iteration: 453; Percent complete: 11.3%; Average loss: 3.4785\n",
      "Iteration: 454; Percent complete: 11.3%; Average loss: 3.2198\n",
      "Iteration: 455; Percent complete: 11.4%; Average loss: 3.3157\n",
      "Iteration: 456; Percent complete: 11.4%; Average loss: 3.4193\n",
      "Iteration: 457; Percent complete: 11.4%; Average loss: 3.0208\n",
      "Iteration: 458; Percent complete: 11.5%; Average loss: 3.5340\n",
      "Iteration: 459; Percent complete: 11.5%; Average loss: 3.3384\n",
      "Iteration: 460; Percent complete: 11.5%; Average loss: 3.4710\n",
      "Iteration: 461; Percent complete: 11.5%; Average loss: 3.4063\n",
      "Iteration: 462; Percent complete: 11.6%; Average loss: 3.4123\n",
      "Iteration: 463; Percent complete: 11.6%; Average loss: 3.4930\n",
      "Iteration: 464; Percent complete: 11.6%; Average loss: 3.2223\n",
      "Iteration: 465; Percent complete: 11.6%; Average loss: 3.4188\n",
      "Iteration: 466; Percent complete: 11.7%; Average loss: 3.2067\n",
      "Iteration: 467; Percent complete: 11.7%; Average loss: 3.1509\n",
      "Iteration: 468; Percent complete: 11.7%; Average loss: 3.3966\n",
      "Iteration: 469; Percent complete: 11.7%; Average loss: 3.3578\n",
      "Iteration: 470; Percent complete: 11.8%; Average loss: 3.7352\n",
      "Iteration: 471; Percent complete: 11.8%; Average loss: 3.1283\n",
      "Iteration: 472; Percent complete: 11.8%; Average loss: 3.3395\n",
      "Iteration: 473; Percent complete: 11.8%; Average loss: 3.5423\n",
      "Iteration: 474; Percent complete: 11.8%; Average loss: 3.4821\n",
      "Iteration: 475; Percent complete: 11.9%; Average loss: 3.2483\n",
      "Iteration: 476; Percent complete: 11.9%; Average loss: 3.2614\n",
      "Iteration: 477; Percent complete: 11.9%; Average loss: 3.8024\n",
      "Iteration: 478; Percent complete: 11.9%; Average loss: 3.0341\n",
      "Iteration: 479; Percent complete: 12.0%; Average loss: 3.4615\n",
      "Iteration: 480; Percent complete: 12.0%; Average loss: 3.3988\n",
      "Iteration: 481; Percent complete: 12.0%; Average loss: 3.3005\n",
      "Iteration: 482; Percent complete: 12.0%; Average loss: 3.1721\n",
      "Iteration: 483; Percent complete: 12.1%; Average loss: 3.1217\n",
      "Iteration: 484; Percent complete: 12.1%; Average loss: 3.1230\n",
      "Iteration: 485; Percent complete: 12.1%; Average loss: 3.4031\n",
      "Iteration: 486; Percent complete: 12.2%; Average loss: 3.4399\n",
      "Iteration: 487; Percent complete: 12.2%; Average loss: 3.0605\n",
      "Iteration: 488; Percent complete: 12.2%; Average loss: 3.3555\n",
      "Iteration: 489; Percent complete: 12.2%; Average loss: 3.4737\n",
      "Iteration: 490; Percent complete: 12.2%; Average loss: 3.6016\n",
      "Iteration: 491; Percent complete: 12.3%; Average loss: 3.4511\n",
      "Iteration: 492; Percent complete: 12.3%; Average loss: 3.5030\n",
      "Iteration: 493; Percent complete: 12.3%; Average loss: 3.0923\n",
      "Iteration: 494; Percent complete: 12.3%; Average loss: 3.3209\n",
      "Iteration: 495; Percent complete: 12.4%; Average loss: 3.4905\n",
      "Iteration: 496; Percent complete: 12.4%; Average loss: 3.4019\n",
      "Iteration: 497; Percent complete: 12.4%; Average loss: 3.3076\n",
      "Iteration: 498; Percent complete: 12.4%; Average loss: 3.3664\n",
      "Iteration: 499; Percent complete: 12.5%; Average loss: 3.3780\n",
      "Iteration: 500; Percent complete: 12.5%; Average loss: 3.3267\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:337] . unexpected pos 147909888 vs 147909792",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/serialization.py:668\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    667\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 668\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:476] . PytorchStreamWriter failed writing file data/27: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 35\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# If you have CUDA, configure CUDA to call\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# for state in encoder_optimizer.state.values():\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     for k, v in state.items():\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Run training iterations\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Training!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtrainIters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m           \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_n_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_n_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m           \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloadFilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[120], line 37\u001b[0m, in \u001b[0;36mtrainIters\u001b[0;34m(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(directory):\n\u001b[1;32m     36\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(directory)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miteration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mde\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_opt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mde_opt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvoc_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.tar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/serialization.py:291\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:337] . unexpected pos 147909888 vs 147909792"
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 4000\n",
    "print_every = 1\n",
    "save_every = 500\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# If you have CUDA, configure CUDA to call\n",
    "# for state in encoder_optimizer.state.values():\n",
    "#     for k, v in state.items():\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             state[k] = v.cuda()\n",
    "\n",
    "# for state in decoder_optimizer.state.values():\n",
    "#     for k, v in state.items():\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             state[k] = v.cuda()\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587848ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dropout layers to ``eval`` mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
